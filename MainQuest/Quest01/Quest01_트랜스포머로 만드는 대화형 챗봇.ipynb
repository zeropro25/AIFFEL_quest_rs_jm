{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ee279c3-375c-457f-9d6c-dfb0a37af60f",
   "metadata": {},
   "source": [
    "# íŠ¸ëœìŠ¤í¬ë¨¸ë¡œ ë§Œë“œëŠ” ëŒ€í™”í˜• ì±—ë´‡ í”„ë¡œì íŠ¸ ğŸŒ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ca2b82-eec8-47e3-9d40-f288310726df",
   "metadata": {},
   "source": [
    "## Transformer ëŒ€ë¹„ ë³€ê²½ì´ í•„ìš”í•œ ë¶€ë¶„\n",
    "\n",
    "**1. ëª¨ë¸ êµ¬ì¡°**\n",
    "- ê¸°ì¡´ í”„ë¡œì íŠ¸ : Encoder + Decoder ë‘ ë¸”ë¡ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "- ë³€ê²½ ë‚´ì—­ : Decoder-only êµ¬ì¡°ë¡œ, Encoder ì œê±°í•œ ë‹¤ìŒ Decoder ë¸”ë¡ë§Œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. Self-Attentionì— ë¯¸ë˜ í† í° ë§ˆìŠ¤í‚¹ ì¶”ê°€ë„ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "**2. ì…ë ¥ í¬ë§·**\n",
    "- ê¸°ì¡´ í”„ë¡œì íŠ¸ : \"USER:\", \"ASSISTANT:\" ì ‘ë‘ì‚¬ë¥¼ ë¬¸ìì—´ ê·¸ëŒ€ë¡œ ë¶™ì—¬ SentencePieceë¡œ í† í°í™”í–ˆìŠµë‹ˆë‹¤.\n",
    "- ë³€ê²½ ë‚´ì—­ : íŠ¹ìˆ˜ ì—­í•  í† í° [USR], [BOT], [DELIM]ì„ ëª…ì‹œì ìœ¼ë¡œ ë¶€ì—¬í•˜ì—¬, ì…ë ¥ì„ [BOS][USR] ì§ˆë¬¸ [DELIM][BOT] ë‹µë³€ [DELIM] â€¦ [EOS] í˜•íƒœë¡œ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "**3. ìœ„ì¹˜ ì •ë³´(Positional Encoding)**\n",
    "- ê¸°ì¡´ í”„ë¡œì íŠ¸ : Transformer ë…¼ë¬¸ê³¼ ë™ì¼í•œ sinusoidal positional encoding ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.\n",
    "- ë³€ê²½ ë‚´ì—­ : í•™ìŠµ ê°€ëŠ¥í•œ positional embedding(pos_emb)ì„ ì¶”ê°€í•˜ì—¬ í† í° ì„ë² ë”©ê³¼ í•©ì‚°í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "**4. í•™ìŠµ ëª©í‘œ**\n",
    "- ê¸°ì¡´ í”„ë¡œì íŠ¸ : Encoder ì…ë ¥(ì§ˆë¬¸) â†’ Decoder ì¶œë ¥(ë‹µë³€) ë°©ì‹ìœ¼ë¡œ sequence-to-sequence í•™ìŠµì´ ëª©í‘œì˜€ìŠµë‹ˆë‹¤.\n",
    "- ë³€ê²½ ë‚´ì—­ : ì…ë ¥ ì „ì²´ ì‹œí€€ìŠ¤ì—ì„œ ë‹¤ìŒ í† í°ì„ ì˜ˆì¸¡í•˜ë„ë¡ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "**5. ì†ì‹¤ ê³„ì‚° ë°©ì‹**\n",
    "- ê¸°ì¡´ í”„ë¡œì íŠ¸ : Decoder ì¶œë ¥ ì „ì²´ì— ëŒ€í•´ ì†ì‹¤ ê³„ì‚°í–ˆìŠµë‹ˆë‹¤.\n",
    "- ë³€ê²½ ë‚´ì—­ : ì‚¬ìš©ì ë°œí™” ë¶€ë¶„ì€ ë§ˆìŠ¤í‚¹í•˜ì—¬ ì†ì‹¤ì—ì„œ ì œì™¸í•˜ê³ , ë‹µë³€ í† í°ë§Œ ì†ì‹¤ ê³„ì‚°í•˜ë„ë¡ í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "**6. ì¶œë ¥ ìƒì„±**\n",
    "- ê¸°ì¡´ í”„ë¡œì íŠ¸ : Greedy Search ë˜ëŠ” ë‹¨ìˆœ ìƒ˜í”Œë§ ê¸°ë°˜ì…ë‹ˆë‹¤.\n",
    "- ë³€ê²½ ë‚´ì—­ : ìƒ˜í”Œë§ ê°•í™” í›„ì— temperature, top-p(nucleus sampling), repetition penalty, stop tokensì„ ì ìš©í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "**7. íŒŒë¼ë¯¸í„° ê³µìœ **\n",
    "- ê¸°ì¡´ í”„ë¡œì íŠ¸ : ì…ë ¥ ì„ë² ë”©ê³¼ ì¶œë ¥ ë ˆì´ì–´(Softmax)ê°€ ë³„ê°œì˜€ìŠµë‹ˆë‹¤.\n",
    "- ë³€ê²½ ë‚´ì—­ : ì„ë² ë”© â†” LM Head weight tying ì ìš©í–ˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca601ea-1827-4f15-8168-722000337741",
   "metadata": {},
   "source": [
    "### 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35529d33-2c74-4d3e-9bb4-7e9c42f42bde",
   "metadata": {},
   "source": [
    "- ```SentencePiece``` : í…ìŠ¤íŠ¸ í† í°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, íŠ¹íˆ í•œêµ­ì–´ì™€ ì¼ë³¸ì–´ ê°™ì´ ë„ì–´ì“°ê¸° êµ¬ë¶„ì´ ì• ë§¤í•œ ì–¸ì–´ì—ì„œ ìì£¼ ì‚¬ìš©ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e16eefe-dd9e-421f-a6c5-4edf07f58c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b102366c-9f45-46a2-bd0e-eaaa86b1fd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒ¨í‚¤ì§€ ì„í¬íŠ¸\n",
    "\n",
    "import os, math, time, random\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10ba4235-85df-40c0-9260-0f465b9dccf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤ë©´?\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d62ef2-e95e-47da-a8c4-0b688fed4d27",
   "metadata": {},
   "source": [
    "### 2. ë°ì´í„° ì „ì²˜ë¦¬í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a5a20e-01e2-4c9d-b030-98870a59cf05",
   "metadata": {},
   "source": [
    "[ì…ë ¥ êµ¬ì„± ë°©ì‹]\n",
    "\n",
    "1. ê¸°ì¡´ í”„ë¡œì íŠ¸\n",
    "- CSVì˜ Q, Aë¥¼ ë¶ˆëŸ¬ì™€ì„œ ê°ê° Encoder ì…ë ¥(ì§ˆë¬¸), Decoder ëª©í‘œ(ë‹µë³€)ìœ¼ë¡œ ë¶„ë¦¬í–ˆìŠµë‹ˆë‹¤.\n",
    "- ì „ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ ì§ˆë¬¸ ì‹œí€€ìŠ¤, ë‹µë³€ ì‹œí€€ìŠ¤ë¥¼ ë”°ë¡œ ë§Œë“¤ì–´ì„œ DataLoaderì— ë„£ì—ˆìŠµë‹ˆë‹¤.\n",
    "- ì…ë ¥ í¬ë§·ì€ \"USER:\" + Q, \"ASSISTANT:\" + A ê°™ì€ ë¬¸ìì—´ ì ‘ë‘ì‚¬ ê¸°ë°˜ì´ì—ˆìŠµë‹ˆë‹¤.\n",
    "- SentencePieceë¡œ subword ë‹¨ìœ„ í† í°í™” â†’ Encoder/Decoder ê°ê° paddingì„ ì ìš©í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "2. ë³€ê²½ ë‚´ì—­\n",
    "- Encoderê°€ ì—†ìœ¼ë¯€ë¡œ Q, Aë¥¼ í•˜ë‚˜ì˜ ì‹œí€€ìŠ¤ë¡œ ì´ì–´ ë¶™ì˜€ìŠµë‹ˆë‹¤.\n",
    "- ```[BOS][USR] Q [DELIM][BOT] A [DELIM] â€¦ [EOS]``` í˜•íƒœë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.\n",
    "- ```DialogDataset``` í´ë˜ìŠ¤ì—ì„œ turn ë‹¨ìœ„ë¡œ ë¬¶ì–´ì„œ block size ê¸°ì¤€ìœ¼ë¡œ ìŠ¬ë¼ì´ì‹±í•©ë‹ˆë‹¤.\n",
    "- xì™€ yëŠ” ë‹¨ì¼ ì‹œí€€ìŠ¤ì—ì„œ shifted LM ë°©ì‹ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c94e9f9-2c91-4a10-a8fc-da86531d81e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/work/0818'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8035b399-c132-4eab-99f7-04ca88aacd21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12ì‹œ ë•¡!</td>\n",
       "      <td>í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´</td>\n",
       "      <td>ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤</td>\n",
       "      <td>ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤</td>\n",
       "      <td>ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL ì‹¬í•˜ë„¤</td>\n",
       "      <td>ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12ì‹œ ë•¡!   í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.      0\n",
       "1      1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´    ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.      0\n",
       "2     3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤  ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .      0\n",
       "3  3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤  ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .      0\n",
       "4          PPL ì‹¬í•˜ë„¤   ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ .      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë°ì´í„°ì…‹ ê²½ë¡œ ì§€ì •\n",
    "CSV_PATH = \"./data/ChatbotData.csv\"\n",
    "\n",
    "# ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# ë°ì´í„° í”„ë ˆì„ì— Q/Aê°€ ë“¤ì–´ì™€ í™•ì¸í•´ì£¼ëŠ” ìš©ë„\n",
    "assert \"Q\" in df.columns and \"A\" in df.columns\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73adedba-180a-472b-b526-6cb369f764eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11750, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12ì‹œ ë•¡!</td>\n",
       "      <td>í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´</td>\n",
       "      <td>ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤</td>\n",
       "      <td>ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Q            A  label\n",
       "0        12ì‹œ ë•¡!   í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.      0\n",
       "1   1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´    ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.      0\n",
       "2  3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤  ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ê¸°ë³¸ ì „ì²˜ë¦¬ - ê²°ì¸¡ì¹˜ì™€ ì¤‘ë³µê°’ ì œê±°\n",
    "\n",
    "df = df.dropna(subset=[\"Q\",\"A\"]).copy()\n",
    "df[\"Q\"] = df[\"Q\"].astype(str).str.strip()\n",
    "df[\"A\"] = df[\"A\"].astype(str).str.strip()\n",
    "df = df.drop_duplicates(subset=[\"Q\",\"A\"]).reset_index(drop=True)\n",
    "\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cab8390-9558-4151-b077-19bf1eaea1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5581, 294)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train / valid ë¶„í• \n",
    "train_df, val_df = train_test_split(df, test_size=0.05, random_state=42, shuffle=True)\n",
    "\n",
    "# ëŒ€í™”ë¥¼ ë¬¶ëŠ” í•¨ìˆ˜ - [(ì§ˆë¬¸, ë‹µë³€)] í˜•íƒœë¡œ ë°˜í™˜\n",
    "def df_to_dialogs(df, turns_per_dialog=2):\n",
    "    pairs = list(zip(df[\"Q\"].tolist(), df[\"A\"].tolist()))\n",
    "    dialogs, buf = [], []\n",
    "    for q,a in pairs:\n",
    "        buf.append((q,a))\n",
    "        if len(buf) == turns_per_dialog:\n",
    "            dialogs.append(buf); buf = []\n",
    "    if buf: dialogs.append(buf)\n",
    "    return dialogs\n",
    "\n",
    "TURNS_PER_DIALOG = 2\n",
    "dialogs_train = df_to_dialogs(train_df, TURNS_PER_DIALOG)\n",
    "dialogs_val   = df_to_dialogs(val_df,   TURNS_PER_DIALOG)\n",
    "len(dialogs_train), len(dialogs_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8f6be2-63c1-497a-a75b-0506a6553589",
   "metadata": {},
   "source": [
    "[íŠ¹ìˆ˜ í† í° ì²˜ë¦¬]\n",
    "\n",
    "1. ê¸°ì¡´ í”„ë¡œì íŠ¸\n",
    "- USER:, ASSISTANT:ëŠ” ê·¸ëƒ¥ ë¬¸ìì—´ì´ë¼ SentencePieceì—ì„œ ì—¬ëŸ¬ subwordë¡œ ë¶„ë¦¬í–ˆì—ˆìŠµë‹ˆë‹¤. (í•™ìŠµ ì‹œ ì˜ë¯¸ í˜¼ë™ ë°œìƒ ê°€ëŠ¥ì„±ì´ ìˆë‹¤ê³  í•©ë‹ˆë‹¤..)\n",
    "- ìœ„ì¹˜ êµ¬ë¶„ì€ ë¬¸ìì—´ íŒ¨í„´ì— ì˜ì¡´í•˜ëŠ” ë°©ì‹ì´ì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "2. ë³€ê²½ ë‚´ì—­\n",
    "- [USR], [BOT], [DELIM]ì„ ë‹¨ì¼ í† í°ìœ¼ë¡œ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.\n",
    "- ì—­í• ê³¼ í„´ ê²½ê³„ë¥¼ ëª…í™•í•˜ê²Œ í•˜ì—¬ ëª¨ë¸ì´ í•™ìŠµí•˜ê¸° ì‰¬ì›Œì§‘ë‹ˆë‹¤.\n",
    "- ë””ì½”ë”© ì‹œì—ë„ ì´ í† í°ë“¤ì„ ì œê±°í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ë§Œ ì¶œë ¥í•˜ë„ë¡ í–ˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5082570a-376d-4262-a03b-e6201905c595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SentencePiece tokenizer, vocab=4003\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "def build_tokenizer(spm_path=\"spm_ko.model\", prefer_sp=True):\n",
    "    if prefer_sp and os.path.exists(spm_path):\n",
    "        # SentencePiece ê°€ì ¸ì˜¤ê¸°\n",
    "        sp = spm.SentencePieceProcessor()\n",
    "        sp.load(spm_path)\n",
    "        sp_vocab = sp.get_piece_size()\n",
    "\n",
    "        # SentencePieceì— íŠ¹ìˆ˜ í† í°ì´ ì—†ë‹¤ë©´ ì¶”ê°€ IDë¥¼ ë’¤ìª½ì— í• ë‹¹\n",
    "        PAD = sp.pad_id() if sp.pad_id() >= 0 else sp_vocab; sp_vocab += (sp.pad_id()<0)\n",
    "        UNK = sp.unk_id() if sp.unk_id() >= 0 else sp_vocab; sp_vocab += (sp.unk_id()<0)\n",
    "        BOS = sp.bos_id() if sp.bos_id() >= 0 else sp_vocab; sp_vocab += (sp.bos_id()<0)\n",
    "        EOS = sp.eos_id() if sp.eos_id() >= 0 else sp_vocab; sp_vocab += (sp.eos_id()<0)\n",
    "\n",
    "        # í„´ êµ¬ë¶„ì ì²˜ë¦¬\n",
    "        DELIM = sp.piece_to_id(\"<DELIM>\") if \"<DELIM>\" in [sp.id_to_piece(i) for i in range(sp.get_piece_size())] else sp_vocab; sp_vocab += (\"<DELIM>\" not in [sp.id_to_piece(i) for i in range(sp.get_piece_size())])\n",
    "\n",
    "        # ì—­í•  í† í° ê²½ê³„ ëª…í™•íˆ í•˜ê¸° (ì§¤ë¦¬ì§€ ì•Šê²Œ)\n",
    "        USR, BOT = sp_vocab, sp_vocab+1\n",
    "        sp_vocab += 2\n",
    "\n",
    "        class SPTokenizer:\n",
    "            def __init__(self, sp):\n",
    "                self.sp=sp; self.PAD=PAD; self.UNK=UNK; self.BOS=BOS; self.EOS=EOS\n",
    "                self.DELIM=DELIM; self.USR=USR; self.BOT=BOT; self.vocab_size=sp_vocab\n",
    "            def encode_text(self,s,add_special=True):\n",
    "                ids=self.sp.encode(s,out_type=int)\n",
    "                return [self.BOS]+ids+[self.EOS] if add_special else ids\n",
    "            def join_with_delim(self,parts):\n",
    "                seq=[]\n",
    "                for i,p in enumerate(parts):\n",
    "                    if i>0: seq.append(self.DELIM)\n",
    "                    seq.extend(p)\n",
    "                return seq\n",
    "            def decode(self,ids):\n",
    "                drop={self.PAD,self.UNK,self.BOS,self.EOS,self.DELIM,self.USR,self.BOT}\n",
    "                keep=[i for i in ids if (i not in drop)]\n",
    "                return self.sp.decode(keep)\n",
    "        print(f\"Loaded SentencePiece tokenizer, vocab={sp_vocab}\")\n",
    "        return SPTokenizer(sp)\n",
    "\n",
    "tok = build_tokenizer(\"spm_ko.model\", prefer_sp=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7106a2bf-4482-476e-94f1-c8b12eff7eb9",
   "metadata": {},
   "source": [
    "[ì†ì‹¤ ê³„ì‚°ìš© ë§ˆìŠ¤í¬]\n",
    "\n",
    "1. ê¸°ì¡´ í”„ë¡œì íŠ¸\n",
    "- Decoderì˜ ëª¨ë“  í† í°(ì§ˆë¬¸ í¬í•¨)ì— ëŒ€í•´ ì†ì‹¤ì„ ê³„ì‚°í–ˆì—ˆìŠµë‹ˆë‹¤.\n",
    "- Qì™€ Aë¥¼ ëª…í™•íˆ ë¶„ë¦¬í–ˆì—ˆê¸°ì— ë”±íˆ ë¬¸ì œê°€ ì—†ì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "2. ë³€ê²½ ë‚´ì—­\n",
    "- ë‹¨ì¼ ì‹œí€€ìŠ¤ ì•ˆì—ì„œ ì‚¬ìš©ì ë°œí™” ë¶€ë¶„ì€ ë§ˆìŠ¤í‚¹í•˜ì—¬ lossì—ì„œ ì œì™¸í–ˆìŠµë‹ˆë‹¤.\n",
    "- ë‹µë³€ í† í° ì˜ˆì¸¡ì—ë§Œ ì§‘ì¤‘í•  ìˆ˜ ìˆë„ë¡ ```mask_user_loss=True``` ì˜µì…˜ì„ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35980b47-2377-4027-a277-4c2afafdcf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogDataset(Dataset):\n",
    "\n",
    "    \"\"\"\n",
    "    ì…ë ¥ ì‹œí€€ìŠ¤ êµ¬ì„± :\n",
    "    [BOS] [USR] user_ids [DELIM] [BOT] answer_ids [DELIM] ... [EOS]\n",
    "    \n",
    "    í•™ìŠµ íƒ€ê¹ƒ(y)ì€ xë¥¼ í•œ ì¹¸ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ë¯¼ í˜•íƒœ(next-token ì˜ˆì¸¡).\n",
    "    mask_user_loss=Trueì´ë©´ ì‚¬ìš©ì êµ¬ê°„ì€ lossì—ì„œ ì œì™¸í•¨(PADë¡œ ë®ì–´ì¨ ignore_index ì²˜ë¦¬).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dialogs, tokenizer, block_size:int, mask_user_loss=True):\n",
    "        self.tok=tokenizer; self.block_size=block_size; self.mask_user_loss=mask_user_loss\n",
    "        self.samples=[]; self.masks=[]\n",
    "        for dialog in dialogs:\n",
    "            ids=[self.tok.BOS]; keep=[False]\n",
    "            for (u,a) in dialog:\n",
    "                u_ids=self.tok.encode_text(u,add_special=False)\n",
    "                a_ids=self.tok.encode_text(a,add_special=False)\n",
    "                ids+=[self.tok.USR]+u_ids+[self.tok.DELIM]+[self.tok.BOT]+a_ids+[self.tok.DELIM]\n",
    "                keep+=[False]+([False]*len(u_ids) if mask_user_loss else [True]*len(u_ids))+[False]+[True]+[True]*len(a_ids)+[False]\n",
    "            ids+=[self.tok.EOS]; keep+=[False]\n",
    "            for i in range(0,len(ids)-1,self.block_size):\n",
    "                chunk=ids[i:i+self.block_size+1]; mchunk=keep[i:i+self.block_size+1]\n",
    "                if len(chunk)<2: break\n",
    "                self.samples.append(chunk); self.masks.append(mchunk)\n",
    "                \n",
    "    def __len__(self): return len(self.samples)\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        seq=self.samples[idx]; m=self.masks[idx]\n",
    "        x=seq[:-1]; y=seq[1:]; m=m[1:]\n",
    "        if len(x)<self.block_size:\n",
    "            pad=self.block_size-len(x)\n",
    "            x+=[self.tok.PAD]*pad; y+=[self.tok.PAD]*pad; m+=[False]*pad\n",
    "        else:\n",
    "            x=x[:self.block_size]; y=y[:self.block_size]; m=m[:self.block_size]\n",
    "\n",
    "        # ì†ì‹¤ ë§ˆìŠ¤í‚¹ : keep=False ìœ„ì¹˜ì˜ íƒ€ê¹ƒì„ PADë¡œ ë®ì–´ì„œ ignore_indexì— ê±¸ë¦¬ê²Œ í•¨\n",
    "        y=[yy if keep else self.tok.PAD for yy,keep in zip(y,m)]\n",
    "        return torch.tensor(x),torch.tensor(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f716b8b-45db-4dba-8e79-12f9c33fd2ed",
   "metadata": {},
   "source": [
    "[ìœ„ì¹˜ ì •ë³´ ì¶”ê°€]\n",
    "\n",
    "1. ê¸°ì¡´ í”„ë¡œì íŠ¸\n",
    "- sinusoidal positional encodingì€ ë³„ë„ ì „ì²˜ë¦¬ ì—†ì´ ëª¨ë¸ forwardì—ì„œ ìë™ ìƒì„±í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "2. ë³€ê²½ ë‚´ì—­\n",
    "- ì „ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ ì‹œí€€ìŠ¤ë¥¼ block_size ë‹¨ìœ„ë¡œ ì˜ë¼ì£¼ê³ , ëª¨ë¸ ë‚´ë¶€ì—ì„œ learned positional embeddingì„ ì‹œí€€ìŠ¤ ê¸¸ì´ì— ë§ì¶° ìë™ìœ¼ë¡œ ë”í–ˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16476a6e-1417-4c33-bc59-f376a1fffd76",
   "metadata": {},
   "source": [
    "### 3. GPT ëª¨ë¸ êµ¬ì„±í•˜ê¸° "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f335210a-7a88-472b-a55c-8faafbb16300",
   "metadata": {},
   "source": [
    "[ì „ì²´ êµ¬ì¡°]\n",
    "\n",
    "1. ê¸°ì¡´ í”„ë¡œì íŠ¸\n",
    "- Encoderì™€ Decoder ë‘ ë¸”ë¡ìœ¼ë¡œ êµ¬ì„±\n",
    "- EncoderëŠ” ì…ë ¥ ì§ˆë¬¸ì„ self-attentionìœ¼ë¡œ ì¸ì½”ë”©, DecoderëŠ” Encoder ì¶œë ¥ì„ cross-attentionìœ¼ë¡œ ì°¸ì¡°í•˜ë©´ì„œ ë‹µë³€ì„ ìƒì„±\n",
    "\n",
    "2. ë³€ê²½ ë‚´ì—­\n",
    "- Decoder-only êµ¬ì¡° (Encoder ì™„ì „íˆ ì œê±°)\n",
    "- Self-Attentionë§Œ ì‚¬ìš©í•˜ë©° ë¯¸ë˜ í† í°ì„ ê°€ë¦¬ëŠ” causal mask ì ìš©\n",
    "- Cross-attentionì´ ì—†ëŠ” ë‹¨ì¼ LM êµ¬ì¡°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "739c10ac-1af5-4104-87e9-88a831a421ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, attn_dropout=0.0, resid_dropout=0.0):\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0\n",
    "        self.n_heads = n_heads\n",
    "        self.d_head = d_model // n_heads\n",
    "        self.qkv = nn.Linear(d_model, 3*d_model, bias=False)\n",
    "        self.proj = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.attn_drop = nn.Dropout(attn_dropout)\n",
    "        self.resid_drop = nn.Dropout(resid_dropout)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        B,T,C = x.size()\n",
    "        qkv = self.qkv(x)\n",
    "        q,k,v = qkv.chunk(3,dim=-1)\n",
    "        q = q.view(B,T,self.n_heads,self.d_head).transpose(1,2)\n",
    "        k = k.view(B,T,self.n_heads,self.d_head).transpose(1,2)\n",
    "        v = v.view(B,T,self.n_heads,self.d_head).transpose(1,2)\n",
    "        att = (q @ k.transpose(-2,-1))/ (self.d_head**0.5)\n",
    "        mask = torch.ones(T,T,device=x.device).triu(1)\n",
    "        att = att.masked_fill(mask.bool(),float(\"-inf\")).softmax(-1)\n",
    "        att = self.attn_drop(att)\n",
    "        y = att @ v\n",
    "        y = y.transpose(1,2).contiguous().view(B,T,C)\n",
    "        return self.resid_drop(self.proj(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "844e2b57-e1be-4ef0-a72d-b97fc37e4b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,d_model,d_ff,dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_model,d_ff),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_ff,d_model),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self,d_model,n_heads,d_ff,attn_dropout=0.0,resid_dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.ln1=nn.LayerNorm(d_model)\n",
    "        self.attn=CausalSelfAttention(d_model,n_heads,attn_dropout,resid_dropout)\n",
    "        self.ln2=nn.LayerNorm(d_model)\n",
    "        self.mlp=MLP(d_model,d_ff,resid_dropout)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82d2b384-9373-4e06-879a-d19874e0b1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT1(nn.Module):\n",
    "    def __init__(self,vocab_size,block_size,n_layer=4,n_head=8,d_model=256,d_ff=1024,\n",
    "                 emb_dropout=0.1,resid_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.vocab_size=vocab_size\n",
    "        self.block_size=block_size\n",
    "        self.tok_emb=nn.Embedding(vocab_size,d_model)\n",
    "        self.pos_emb=nn.Embedding(block_size,d_model)\n",
    "        self.drop=nn.Dropout(emb_dropout)\n",
    "        self.blocks=nn.ModuleList([Block(d_model,n_head,d_ff,0.1,resid_dropout) for _ in range(n_layer)])\n",
    "        self.ln_f=nn.LayerNorm(d_model)\n",
    "        self.lm_head=nn.Linear(d_model,vocab_size,bias=False)\n",
    "        self.lm_head.weight=self.tok_emb.weight\n",
    "        self.apply(self._init)\n",
    "        \n",
    "    def _init(self,m):\n",
    "        if isinstance(m,(nn.Linear,nn.Embedding)):\n",
    "            nn.init.normal_(m.weight,mean=0.0,std=0.02)\n",
    "        if isinstance(m,nn.Linear) and m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "            \n",
    "    def forward(self,idx,targets=None):\n",
    "        B,T=idx.size()\n",
    "        assert T<=self.block_size\n",
    "        pos=torch.arange(T,device=idx.device).unsqueeze(0) # Positional Encoding\n",
    "        x=self.tok_emb(idx)+self.pos_emb(pos)\n",
    "        x=self.drop(x)\n",
    "        for blk in self.blocks: x=blk(x)\n",
    "        x=self.ln_f(x)\n",
    "        logits=self.lm_head(x)\n",
    "        loss=None\n",
    "        if targets is not None:\n",
    "            PAD=getattr(tok,\"PAD\",0)\n",
    "            loss=F.cross_entropy(logits.view(-1,logits.size(-1)),targets.view(-1),ignore_index=PAD)\n",
    "        return logits,loss\n",
    "        \n",
    "    def summary_text(self):\n",
    "        params=sum(p.numel() for p in self.parameters())\n",
    "        return (\n",
    "            f\"GPT1(vocab={self.vocab_size},block={self.block_size},layers={len(self.blocks)})\\\\n\"\n",
    "            f\"d_model={self.tok_emb.embedding_dim}, d_ff={self.blocks[0].mlp.net[0].out_features}\\\\n\"\n",
    "            f\"params={params:,}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6edeac7a-8890-466d-b413-98c86276e6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class HParams:\n",
    "    block_size:int=256      # í•œ ì‹œí€€ìŠ¤ ìµœëŒ€ í† í° ê¸¸ì´\n",
    "    batch_size:int=32       # í•™ìŠµ ë¯¸ë‹ˆë°°ì¹˜ í¬ê¸°\n",
    "    n_layer:int=8           # Transformer Block ê°œìˆ˜ (ê¹Šì´)\n",
    "    n_head:int=8            # Multi-Head Attentionì˜ head ìˆ˜\n",
    "    d_model:int=512         # ì„ë² ë”© ì°¨ì› (í† í° ë²¡í„° ì°¨ì›)\n",
    "    d_ff:int=2048           # í”¼ë“œí¬ì›Œë“œ ë ˆì´ì–´ ì°¨ì› (í™•ì¥ëœ ì°¨ì›)\n",
    "    emb_dropout:float=0.1   # ì„ë² ë”© ì…ë ¥ ì§í›„ dropout ë¹„ìœ¨\n",
    "    resid_dropout:float=0.1 # ë¸”ë¡ ë‚´ residual connection ë’¤ dropout ë¹„ìœ¨\n",
    "    lr:float=2e-4           # AdamW í•™ìŠµë¥ \n",
    "    weight_decay:float=0.01 # AdamW ì •ê·œí™” (ê°€ì¤‘ì¹˜ ê°ì‡ )\n",
    "    epochs:int=15           # í•™ìŠµ epoch ìˆ˜\n",
    "    device:str=device       # \"cuda\" ë˜ëŠ” \"cpu\"\n",
    "    \n",
    "    def model_kwargs(self):\n",
    "        return dict(block_size=self.block_size,n_layer=self.n_layer,n_head=self.n_head,\n",
    "                    d_model=self.d_model,d_ff=self.d_ff,\n",
    "                    emb_dropout=self.emb_dropout,resid_dropout=self.resid_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45912d53-4c4b-4c8f-903f-17d3ecc54014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_repetition_penalty(logits, prev_ids, penalty=1.1):\n",
    "    if penalty==1.0 or prev_ids is None: return logits\n",
    "    uniq=torch.unique(prev_ids)\n",
    "    logits[:,uniq]/=penalty\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eda5970-d1d1-40c0-a2fb-0fa8fd51f3ed",
   "metadata": {},
   "source": [
    "- ```generate``` : ì¶”ë¡  ì „ìš©(no_grad) ìƒì„± í•¨ìˆ˜\n",
    "- ```idx``` : í˜„ì¬ê¹Œì§€ì˜ í† í°(ë°°ì¹˜ 1Ã—ê¸¸ì´)\n",
    "- ```max_new_tokens``` : ìƒˆë¡œ ë§Œë“¤ ìµœëŒ€ í† í° ìˆ˜\n",
    "- ```temperature/top_p``` : ìƒ˜í”Œë§ ì œì–´\n",
    "- ```repetition_penalty``` : ë°˜ë³µ ì–µì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c49b03e-b753-4904-b3cf-072285f8eb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate(model, idx, max_new_tokens=64, temperature=0.8, top_p=0.9, repetition_penalty=1.1, stop_ids=None):\n",
    "    model.eval()\n",
    "    stop_ids=set(stop_ids or [])\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond=idx[:,-model.block_size:]\n",
    "        logits,_=model(idx_cond)\n",
    "        logits=logits[:,-1,:]\n",
    "        logits=apply_repetition_penalty(logits,idx,penalty=repetition_penalty)\n",
    "        logits=logits/temperature\n",
    "        probs=torch.softmax(logits,dim=-1)\n",
    "        sorted_probs,sorted_idx=torch.sort(probs,descending=True)\n",
    "        cum=torch.cumsum(sorted_probs,dim=-1)\n",
    "        mask=cum>top_p; mask[...,0]=False\n",
    "        sorted_probs[mask]=0\n",
    "        sorted_probs/=sorted_probs.sum(-1,keepdim=True)\n",
    "        next_sorted=torch.multinomial(sorted_probs,1)\n",
    "        next_id=sorted_idx.gather(-1,next_sorted)\n",
    "        idx=torch.cat([idx,next_id],dim=1)\n",
    "        token=int(next_id.item())\n",
    "        if token in stop_ids or token==getattr(tok,\"EOS\",None):\n",
    "            break\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb94f9ac-8ca5-4299-839c-30d5390b765e",
   "metadata": {},
   "source": [
    "### 4. ëª¨ë¸ í‰ê°€í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9568b9-54e7-4807-b67e-208555d4ee5d",
   "metadata": {},
   "source": [
    "[ì¶œë ¥ ìƒì„±]\n",
    "\n",
    "1. ê¸°ì¡´ í”„ë¡œì íŠ¸\n",
    "- ì£¼ë¡œ Greedy searchë¥¼ ì‚¬ìš©í–ˆì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "2. ë³€ê²½ ë‚´ì—­\n",
    "- ìƒ˜í”Œë§ ê¸°ë°˜ ìƒì„±(temperature, top-p, reptition penalty, stop_ids)ì„ ì ìš©í–ˆìŠµë‹ˆë‹¤.\n",
    "- ë°˜ë³µì„ ì¤„ì´ê³  ë‹¤ì–‘í•œ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ìˆë„ë¡ í–ˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74314299-1681-4567-95c9-eeb526e27e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== model.summary ===\n",
      "GPT1(vocab=4003,block=256,layers=8)\\nd_model=512, d_ff=2048\\nparams=27,384,320\n",
      "Epoch 1/15 - 82.8s - loss:5.3557 - val:4.9030\n",
      "Epoch 2/15 - 82.5s - loss:4.7257 - val:4.5055\n",
      "Epoch 3/15 - 82.6s - loss:4.3352 - val:4.2298\n",
      "Epoch 4/15 - 82.7s - loss:4.0591 - val:4.0490\n",
      "Epoch 5/15 - 82.6s - loss:3.8397 - val:3.9303\n",
      "Epoch 6/15 - 82.6s - loss:3.6336 - val:3.8477\n",
      "Epoch 7/15 - 82.4s - loss:3.4323 - val:3.7742\n",
      "Epoch 8/15 - 82.5s - loss:3.2129 - val:3.7392\n",
      "Epoch 9/15 - 82.5s - loss:2.9880 - val:3.6595\n",
      "Epoch 10/15 - 82.6s - loss:2.7412 - val:3.6389\n",
      "Epoch 11/15 - 82.8s - loss:2.4942 - val:3.6096\n",
      "Epoch 12/15 - 82.8s - loss:2.2295 - val:3.6010\n",
      "Epoch 13/15 - 82.8s - loss:1.9649 - val:3.5976\n",
      "Epoch 14/15 - 82.8s - loss:1.6985 - val:3.5984\n",
      "Epoch 15/15 - 82.7s - loss:1.4400 - val:3.5836\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„°ì…‹/ë¡œë” ì¤€ë¹„\n",
    "h=HParams()\n",
    "model=GPT1(vocab_size=tok.vocab_size,**h.model_kwargs()).to(h.device)\n",
    "train_ds=DialogDataset(dialogs_train,tok,h.block_size,mask_user_loss=True)\n",
    "val_ds=DialogDataset(dialogs_val,tok,h.block_size,mask_user_loss=True)\n",
    "train_dl=torch.utils.data.DataLoader(train_ds,batch_size=h.batch_size,shuffle=True)\n",
    "val_dl=torch.utils.data.DataLoader(val_ds,batch_size=h.batch_size)\n",
    "\n",
    "print(\"=== model.summary ===\")\n",
    "print(model.summary_text())\n",
    "\n",
    "opt=torch.optim.AdamW(model.parameters(),lr=h.lr,weight_decay=h.weight_decay)\n",
    "\n",
    "for ep in range(1,h.epochs+1):\n",
    "    model.train(); tot=0;n=0;t0=time.time()\n",
    "    for xb,yb in train_dl:\n",
    "        xb,yb=xb.to(h.device),yb.to(h.device)\n",
    "        opt.zero_grad();_,loss=model(xb,yb)\n",
    "        loss.backward(); opt.step()\n",
    "        tot+=float(loss.item())*xb.size(0); n+=xb.size(0)\n",
    "    tr_loss=tot/max(1,n)\n",
    "    model.eval();vt=0;vn=0\n",
    "    with torch.no_grad():\n",
    "        for xb,yb in val_dl:\n",
    "            xb,yb=xb.to(h.device),yb.to(h.device)\n",
    "            _,vloss=model(xb,yb)\n",
    "            vt+=float(vloss.item())*xb.size(0); vn+=xb.size(0)\n",
    "    print(f\"Epoch {ep}/{h.epochs} - {time.time()-t0:.1f}s - loss:{tr_loss:.4f} - val:{vt/max(1,vn):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a694b7d-5af0-4f3c-9b9b-6a8a2a1fe9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: ì‚¬ë‘ì´ë€ ë­˜ê¹Œ?\n",
      "A: ì‚¬ë‘ì´ë€ ë­˜ê¹Œ? ì§ì ‘ ë¬¼ì–´ë³´ì„¸ìš”. ì°¨ë¶„íˆ ë‹¹ë‹¹í•˜ê²Œ ë§í•´ë³´ì„¸ìš”. ê·¸ë ‡ì§€ ì•Šì•„ìš”. ë¬´ì—‡ì´ ê°™ì´ ë“¤ì–´ì§ˆê²Œìš”. ê³ ë¯¼ë§Œ ìˆë‹¤ë©´ ë‹¹ì‹ ì„ ìƒê°í•´ë³´ì„¸ìš”. ì¶©ë¶„íˆ ê·¸ëŸ´ê²Œìš”. í˜ë“¤ì—ˆì„ê±°ë¼ ìƒê°í•´ìš”. ë‚´ì„¸ìš”. ì‹ ê²½ì“°ì§€ ë§ˆì„¸ìš”. ìì—°ìŠ¤ëŸ¬í•©ë‹ˆë‹¤. ê¸°ë‹¤ë¦¬ì„¸ìš”. í›„íšŒí•´ì¡Œí•˜ëŠ” ê±´ ì—†ì–´ìš”. ìˆì–´ìš”. ì´ë³„ì´ì—ˆì„? ìƒê°í•´ ë³¼ê²Œìš”. ì¢‹ì•„í•˜ëŠ” ê¸°ì–µìœ¼ë¡œ ì•„íŒŒí•˜ê²Œ í‘œí˜„í•´ë³´ëŠ” ê²ƒë„ ì¤‘ìš”í•œ ê²ƒ ê°™ë„¤ ë„ì™€ì£¼ëŠ”\n"
     ]
    }
   ],
   "source": [
    "# ìƒì„± í…ŒìŠ¤íŠ¸\n",
    "q=val_df.iloc[0][\"Q\"]\n",
    "ids=[getattr(tok,\"BOS\",0),getattr(tok,\"USR\",1)]+tok.encode_text(q,add_special=False)+[getattr(tok,\"BOT\",2)]\n",
    "idx=torch.tensor([ids],dtype=torch.long,device=h.device)\n",
    "out=generate(model,idx,max_new_tokens=80,temperature=0.8,top_p=0.9,repetition_penalty=1.1,\n",
    "             stop_ids={getattr(tok,\"USR\",-1),getattr(tok,\"DELIM\",-1)})\n",
    "print(\"Q:\",q)\n",
    "print(\"A:\",tok.decode(out[0].tolist()).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c360a06-bbd6-41bf-b0c3-4afa529e89a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
